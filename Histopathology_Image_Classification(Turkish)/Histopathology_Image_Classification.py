# -*- coding: utf-8 -*-
"""Untitled17 (4).ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1aJ_Q6SZk7Rf1nsJf1p-vLh0BLscOrg5V
"""

!nvidia-smi

# Download Data
!wget https://uc7f2de64808e3ad622e0e73ff30.dl.dropboxusercontent.com/cd/0/get/Bd9MnZtW6uOq9r6rsAE-hjPN6GziAhrmEcymfyLw-p18_jTE5nzVhQs56vIq8ufCZnIKTH7KRWJ1DH_CLoN7H4qXj57sB2MMlRa68zOC0giyYIXpNXpSmEdi-w58LCGPWe8iAssEDcTuzm0v7QwIObpo/file
!wget https://ucc21454f7c0e7da4ebb44807d0c.dl.dropboxusercontent.com/cd/0/get/Bd_piPv_wV_hu4SV-kkmChHC-s0rKrGU-E9LVyiWDpCQjVdBg3FYLMMcm0eRScJPysSrKLaWo7njO7g5TclLVsVEQjvA1tX20SapFdcreXmXiX6jSnc1K3WeCOcytSCHGlCmUT9yuMeopOu2UQl3iKe8/file
!unzip file
!mv file.1 annotations.csv

!pip install git+https://github.com/rwightman/pytorch-image-models.git
!pip install -U albumentations -q
!pip uninstall opencv-python-headless
!pip install opencv-python-headless==4.1.2.30

import torch
import torch.nn as nn
from torch.utils.data import Dataset, DataLoader
from sklearn.model_selection import train_test_split
import numpy as np
from tqdm import tqdm
import cv2
import pandas as pd
import os
import random
import timm
import albumentations as A
from albumentations.pytorch import ToTensorV2
import matplotlib.pyplot as plt
import seaborn as sns
sns.set()

cfg_dict = {
    "model": "seresnext26d_32x4d",
    "batch_size": 8,
    "learning_rate": 3e-4,
    "weight_decay": 0,
    "img_size": 224,
    "early_stopping": 15
}


def seed_everything(seed=42):
    random.seed(seed)
    os.environ['PYTHONHASHSEED'] = str(seed)
    np.random.seed(seed)
    torch.manual_seed(seed)
    torch.cuda.manual_seed(seed)
    torch.backends.cudnn.deterministic = True
    torch.backends.cudnn.benchmark = True


def split_df(df):
    x_train, x_test = train_test_split(
        df, test_size=0.2, random_state=42)
    return x_train, x_test


def get_img(path):
    img = cv2.imread(path)
    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
    return img


class ClassificationDataset(Dataset):
    def __init__(self, df: pd.DataFrame, data_dir: str,
                 train: bool,
                 transforms=None) -> None:
        super().__init__()
        self.df = df
        self.data_dir = data_dir
        self.transforms = transforms
        self.train = train

    def __len__(self):
        return self.df.shape[0]

    def __getitem__(self, index: int):
        img = get_img("{}/{}".format(self.data_dir, self.df.loc[index]["Image Name"]))
        if self.transforms:
            img = self.transforms(image=img)["image"]

        if self.train:
            target = self.df.loc[index]["Majority Vote Label"]
            if target == "HP":
                target = 0
            elif target == "SSA":
                target = 1
            else:
                raise NotImplementedError("Unknown Label")
            return img, target
        else:
            return img


def get_train_transforms():
    return A.Compose([
            A.VerticalFlip(p=0.5),
            A.HorizontalFlip(p=0.5),
            A.ShiftScaleRotate(
                    scale_limit=0.1,  # 0
                    shift_limit=0.1,  # 0.05
                    rotate_limit=90,
                    p=0.5,
                ),
            deformation_transform(p=0.5),
            color_transforms(p=0.5),
            blur_transforms(p=0.5),
        A.Normalize(mean=[0.485, 0.456, 0.406],
                    std=[0.229, 0.224, 0.225]),
        ToTensorV2(p=1.0)
    ], p=1.)


def get_valid_transforms():
    return A.Compose([
        A.Normalize(mean=[0.485, 0.456, 0.406],
                    std=[0.229, 0.224, 0.225]),
        ToTensorV2(p=1.0),
    ], p=1.)


def plot_acc(train_acc, val_acc):
    plt.figure(figsize=(10,5))
    plt.title("Train and Validation Accuracy")
    plt.plot(train_acc, label="Train Accuracy")
    plt.plot(val_acc, label="Val Accuracy")
    plt.xlabel("Epochs")
    plt.legend()
    plt.show()

def plot_loss(train_loss, val_loss):
    plt.figure(figsize=(10,5))
    plt.title("Train and Validation Loss")
    plt.plot(train_loss, label="Train Loss")
    plt.plot(val_loss, label="Val Loss")
    plt.xlabel("Epochs")
    plt.legend()
    plt.show()


class ClassifierModel(nn.Module):
    def __init__(self, arch, n_class, pretrained=False):
        super().__init__()
        self.model = timm.create_model(arch, pretrained=pretrained, num_classes=4)
        if "nfnet" in arch:
            n_features = self.model.head.fc.in_features
            self.model.head.fc = nn.Linear(n_features, n_class)

        elif "efficientnet" in arch:
            n_features = self.model.classifier.in_features
            self.model.classifier = nn.Linear(n_features, n_class)

        elif "mixer" in arch:
            n_features = self.model.head.in_features
            self.model.head = nn.Linear(n_features, n_class)
            print(self.model.head)


    def forward(self, x):
        x = self.model(x)
        return x


def prepare_dataloader(trn_df, val_df, batch_size, data_root):
    trn_df = trn_df.reset_index(drop=True)
    val_df = val_df.reset_index(drop=True)

    train_ds = ClassificationDataset(df=trn_df, data_dir=data_root,
                                    train=True, transforms=get_train_transforms())
    valid_ds = ClassificationDataset(df=val_df, data_dir=data_root,
                              train=True, transforms=get_valid_transforms())

    train_loader = DataLoader(
        dataset=train_ds,
        batch_size=batch_size,
        pin_memory=True,
        drop_last=False,
        num_workers=2,
        shuffle=True
    )

    val_loader = DataLoader(
        dataset=valid_ds,
        batch_size=batch_size,
        pin_memory=True,
        shuffle=False,
        num_workers=2
    )
    return train_loader, val_loader

from albumentations.core.transforms_interface import ImageOnlyTransform


def disk(radius, alias_blur=0.1, dtype=np.float32):
    """
    From https://github.com/hendrycks/robustness/blob/master/ImageNet-C/create_c/make_imagenet_c.py
    and https://github.com/albumentations-team/albumentations/issues/477
    """
    if radius <= 8:
        L = np.arange(-8, 8 + 1)
        ksize = (3, 3)
    else:
        L = np.arange(-radius, radius + 1)
        ksize = (5, 5)
    X, Y = np.meshgrid(L, L)
    aliased_disk = np.array((X ** 2 + Y ** 2) <= radius ** 2, dtype=dtype)
    aliased_disk /= np.sum(aliased_disk)

    # supersample disk to antialias
    return cv2.GaussianBlur(aliased_disk, ksize=ksize, sigmaX=alias_blur)


class DefocusBlur(ImageOnlyTransform):
    """
    From https://github.com/hendrycks/robustness/blob/master/ImageNet-C/create_c/make_imagenet_c.py
    and https://github.com/albumentations-team/albumentations/issues/477
    """
    def __init__(
        self,
        severity=1,
        always_apply=False,
        p=1.0,
    ):
        super(DefocusBlur, self).__init__(always_apply, p)
        self.severity = severity
        self.radius, self.blur = [(3, 0.1), (4, 0.5), (6, 0.5), (8, 0.5), (10, 0.5)][
            self.severity - 1
        ]

    def apply(self, image, **params):
        image = np.array(image) / 255.0
        kernel = disk(radius=self.radius, alias_blur=self.blur)
        channels = []
        for d in range(3):
            channels.append(cv2.filter2D(image[:, :, d], -1, kernel))
        channels = np.array(channels).transpose((1, 2, 0))
        return np.clip(channels, 0, 1) * 255

    def get_transform_init_args_names(self):
        return "severty"


def blur_transforms(p=0.5, blur_limit=5, gaussian_limit=(5, 7), severity=1):
    """
    Applies MotionBlur or GaussianBlur random with a probability p.
    Args:
        p (float, optional): probability. Defaults to 0.5.
        blur_limit (int, optional): Blur intensity limit. Defaults to 5.
    Returns:
        albumentation transforms: transforms.
    """
    return A.OneOf(
        [
            DefocusBlur(severity=severity, always_apply=True),
            A.MotionBlur(blur_limit=blur_limit, always_apply=True),
            A.GaussianBlur(blur_limit=gaussian_limit, always_apply=True),
        ],
        p=p,
    )


def noise_transforms(p=0.5):
    """
    Applies GaussNoise or RandomFog random with a probability p.
    Args:
        p (float, optional): probability. Defaults to 0.5.
    Returns:
        albumentation transforms: transforms.
    """
    return A.OneOf(
        [
            A.GaussNoise(var_limit=(1.0, 50.0), always_apply=True),
            A.RandomFog(fog_coef_lower=0.01, fog_coef_upper=0.25, always_apply=True),
        ],
        p=p,
    )


def color_transforms(p=0.5):
    """
    Applies RandomGamma or RandomBrightnessContrast random with a probability p.
    Args:
        p (float, optional): probability. Defaults to 0.5.
    Returns:
        albumentation transforms: transforms.
    """
    return A.OneOf(
        [
            A.Compose(
                [
                    A.RandomGamma(gamma_limit=(80, 120), p=1),
                    A.RandomBrightnessContrast(
                        brightness_limit=0.1,  # 0.3
                        contrast_limit=0.1,  # 0.3
                        p=1,
                    ),
                ]
            ),
            A.RGBShift(
                r_shift_limit=30,
                g_shift_limit=0,
                b_shift_limit=30,
                p=1,
            ),
            A.HueSaturationValue(
                hue_shift_limit=30,
                sat_shift_limit=30,
                val_shift_limit=30,
                p=1,
            ),
            A.ColorJitter(
                brightness=0.3,  # 0.3
                contrast=0.3,  # 0.3
                saturation=0.3,
                hue=0.05,
                p=1,
            ),
        ],
        p=p,
    )


def deformation_transform(p=0.5):
    """
    Applies ElasticTransform, GridDistortion or OpticalDistortion with a probability p.
    Args:
        p (float, optional): probability. Defaults to 0.5.
    Returns:
        albumentation transforms: transforms.
    """
    return A.OneOf(
        [
            A.ElasticTransform(
                alpha=1,
                sigma=25,
                alpha_affine=25,
                border_mode=cv2.BORDER_CONSTANT,
                value=0,
                always_apply=True,
            ),
            A.GridDistortion(always_apply=True),
            A.OpticalDistortion(distort_limit=1, shift_limit=0.2, always_apply=True),
        ],
        p=p,
    )

def train_one_epoch(epoch, model, loss_fn, optimizer, train_loader):
    model.train()
    losses = []
    image_preds_all = []
    image_targets_all = []
    pbar = tqdm(enumerate(train_loader), total=len(train_loader), position=0)
    for step, (imgs, img_labels) in pbar:
        imgs = imgs.to(device)
        img_labels = img_labels.to(device)
        img_preds = model(imgs)

        image_preds_all += [torch.argmax(img_preds, 1).detach().cpu().numpy()]
        image_targets_all += [img_labels.detach().cpu().numpy()]
        loss = loss_fn(img_preds, img_labels)
        loss.backward()
        optimizer.step()

        losses.append(loss.item())
        smooth_loss = np.mean(losses[-30:])
        optimizer.zero_grad()

        if ((step + 1) % 1 == 0) or ((step + 1) == len(train_loader)):
            description = f"epoch {epoch}, loss: {loss.item():.4f}, smth_loss: {smooth_loss:.4f}"
            pbar.set_description(description)

    image_preds_all = np.concatenate(image_preds_all)
    image_targets_all = np.concatenate(image_targets_all)
    print("\ntrain accuracy: {}".format((image_preds_all == image_targets_all).mean()))
    loss_train = np.mean(losses)
    return loss_train, (image_preds_all == image_targets_all).mean()


def valid_one_epoch(epoch, model, loss_fn, val_loader):
    model.eval()
    losses = []
    image_preds_all = []
    image_targets_all = []
    pbar = tqdm(enumerate(val_loader), total=len(val_loader), position=0)
    with torch.no_grad():
        for step, (imgs, img_labels) in pbar:
            imgs = imgs.to(device)
            img_labels = img_labels.to(device)
            image_preds = model(imgs)
            image_preds_all += [torch.argmax(image_preds, 1).detach().cpu().numpy()]
            image_targets_all += [img_labels.detach().cpu().numpy()]
            loss = loss_fn(image_preds, img_labels)

            losses.append(loss.item())
            smooth_loss = np.mean(losses[-30:])

            if ((step + 1) % 1 == 0) or ((step + 1) == len(val_loader)):
                description = f"epoch {epoch}, val_loss: {loss.item():.4f}, smth_val_loss:{smooth_loss:.4f}"
                pbar.set_description(description)

    image_preds_all = np.concatenate(image_preds_all)
    image_targets_all = np.concatenate(image_targets_all)
    print("\nvalidation accuracy: {}".format((image_preds_all == image_targets_all).mean()))
    loss_valid = np.mean(losses)
    return loss_valid, (image_preds_all == image_targets_all).mean()


if __name__ == "__main__":
    seed_everything()
    val_acc_best = 0
    train_loss_all = []
    train_acc_all = []
    val_loss_all = []
    val_acc_all = []
    data_path = "/content/images"
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    df = pd.read_csv("annotations.csv")
    train_df, test_df = split_df(df)
    train_loader, val_loader = prepare_dataloader(train_df, test_df, cfg_dict["batch_size"], data_path)
    model = ClassifierModel(cfg_dict["model"], 2, pretrained=True).to(device)
    optimizer = torch.optim.Adam(model.parameters(), lr=cfg_dict["learning_rate"], weight_decay=cfg_dict["weight_decay"])
    loss_fn = nn.CrossEntropyLoss()
    for epoch in range(500):
        train_loss, train_acc = train_one_epoch(epoch=epoch, model=model, loss_fn=loss_fn, optimizer=optimizer,
                        train_loader=train_loader)
        val_loss, val_acc = valid_one_epoch(epoch=epoch, model=model, loss_fn=loss_fn, val_loader=val_loader)
        train_loss_all.append(train_loss); train_acc_all.append(train_acc); val_loss_all.append(val_loss_all); val_acc_all.append(val_acc)
        if val_acc > val_acc_best:
            print(f"Epoch {epoch}, Metric improved from {val_acc_best:.4f} to -> {val_acc:.4f}. Saving model")
            torch.save(model.state_dict(), f"{cfg_dict['model']}_epoch_{epoch}_acc_{val_acc:.4f}_loss_{val_loss:.4f}")
            val_acc_best = val_acc
            not_improving = 0
        if val_acc < val_acc_best:
            not_improving += 1
        print(
            f"Epoch {epoch}: train_loss: {train_loss:.4f}, val_loss: {val_loss:.4f}, train_acc: {train_acc:.4f}, val_acc: {val_acc:.4f} Early Stopping round: {not_improving}")
        if cfg_dict["early_stopping"] == not_improving:
            print("Early Stopping")
            print(f"Best accuracy was {val_acc_best} at epoch {epoch - 15}")
            break
    torch.cuda.empty_cache()
    #plot_acc(train_acc_all, val_acc_all)
    #plot_loss(train_loss_all, val_loss_all)

from sklearn.metrics import confusion_matrix, classification_report, roc_auc_score
import seaborn as sns
import matplotlib.pyplot as plt

sns.set()
cmap = sns.diverging_palette(150, 10, as_cmap=True)

def valid_one_epoch_last(epoch, model, loss_fn, val_loader):
    model.eval()
    losses = []
    image_preds_all = []
    image_targets_all = []
    pbar = tqdm(enumerate(val_loader), total=len(val_loader), position=0)
    with torch.no_grad():
        for step, (imgs, img_labels) in pbar:
            imgs = imgs.to(device)
            img_labels = img_labels.to(device)
            image_preds = model(imgs)
            image_preds_all += [torch.argmax(image_preds, 1).detach().cpu().numpy()]
            image_targets_all += [img_labels.detach().cpu().numpy()]
            loss = loss_fn(image_preds, img_labels)

            losses.append(loss.item())

            smooth_loss = np.mean(losses[-30:])

            if ((step + 1) % 1 == 0) or ((step + 1) == len(val_loader)):
                description = f"epoch {epoch}, val_loss: {loss.item():.4f}, smth_val_loss:{smooth_loss:.4f}"
                pbar.set_description(description)

    image_preds_all = np.concatenate(image_preds_all)
    image_targets_all = np.concatenate(image_targets_all)
    cm = confusion_matrix(image_targets_all, image_preds_all)
    sns.heatmap(cm, annot=True, cmap=cmap, fmt="g")
    plt.show()
    print(classification_report(image_targets_all, image_preds_all, labels=[0,1]))
    print("\nvalidation accuracy: {}".format((image_preds_all == image_targets_all).mean()))
    print("\nvalidation auc: {}".format(roc_auc_score(image_targets_all, image_preds_all)))
    loss_valid = np.mean(losses)
    return loss_valid, (image_preds_all == image_targets_all).mean(), cm, image_preds_all, image_targets_all

seed_everything()
data_path = "/content/images/"
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
df = pd.read_csv("annotations.csv")
train_df, test_df = split_df(df)
train_loader, val_loader = prepare_dataloader(train_df, test_df, cfg_dict["batch_size"], data_path)
model = ClassifierModel(cfg_dict["model"], 2, pretrained=False).to(device)
model.load_state_dict(torch.load("/content/seresnext26d_32x4d_epoch_46_acc_0.9033_loss_0.3028"))
loss_fn = nn.CrossEntropyLoss()
val_loss, val_acc, cm, image_preds_all, image_targets_all = valid_one_epoch_last(epoch=0, model=model, loss_fn=loss_fn, val_loader=val_loader)